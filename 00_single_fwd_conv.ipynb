{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26febc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.1\n"
     ]
    }
   ],
   "source": [
    "import cudnn\n",
    "print(cudnn.__version__)\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8aca43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn.backend_version(): 91301\n",
      "torch.version.cuda: 12.8\n"
     ]
    }
   ],
   "source": [
    "device: torch.cuda.device = torch.device(\"cuda\")\n",
    "print(f\"cudnn.backend_version(): {cudnn.backend_version()}\")\n",
    "print(f\"torch.version.cuda: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50469386",
   "metadata": {},
   "source": [
    "#### Initialise CUDNN Handle\n",
    "\n",
    "Initialises the library's context, it acts as an identifier for the current session with cuDNN. In the back-end, under underlying handle is explicitly passed to every subsequent library function that operates on GPU data. This provides the user with a means to explicitly control the library's functioning across multiple host threads, GPUs and CUDA streams. \n",
    "e.g. using cudaSetDevice can associate different physical GPUs with different host threads. With a different handle initialised in each host thread, the work from each different host thread will automatically run on different GPU devices\n",
    "\n",
    "The handle is used to determine on which GPU the kernel will be launched. The context is only associated wtih a single physical GPU device, however multiple handles can be initialised for a single physical GPU device.\n",
    "\n",
    "Front-end docs: https://docs.nvidia.com/deeplearning/cudnn/frontend/latest/developer/core-concepts.html#cudnn-handle \\\n",
    "Back-end docs: https://docs.nvidia.com/deeplearning/cudnn/backend/latest/developer/core-concepts.html#cudnn-handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c15ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = cudnn.create_handle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a46b0",
   "metadata": {},
   "source": [
    "#### Initialise CUDNN Graph\n",
    "\n",
    "CUDNN provides a eclarative programming model, computation is defined via a graph of operations (on tensors), the CUDNN back-end handles how it is executed on the GPU device. Graphs are comprised of three main concepts, Operations, Execution Engines and Heuristics.\n",
    "\n",
    "*Operations* are a mathematical specification of the operations being executed.\\\n",
    "*Execution Engines*: Different engines support the execution of different operations, from the documentation:\n",
    "\n",
    ">pre-compiled single operation engines, generic runtime fusion engines, specialized runtime fusion engines, and specialized pre-compiled fusion engines. The specialized engines, whether they use runtime compilation or pre-compilation, are targeted to a set of important use cases, and thus have a fairly limited set of patterns they currently support. Over time, we expect to support more of those use cases with the generic runtime fusion engines, whenever practical.\n",
    "\n",
    "*Heuristics*: Depending on the graph there might be zero, one or multiple engines that can execute a graph. Heuristics give a way of sorting viable execution engines from most to least performant, on a specific operation graph.\n",
    "\n",
    "> 1. Heuristics Mode A - intended to be fast and be able to handle most operation graph patterns. It returns a list of engine configs ranked by the expected performance.\n",
    "> 2. Heuristics Mode B - intended to be more generally accurate than mode A, but with the tradeoff of higher CPU latency to return the list of engine configs. The underlying implementation may fall back to the mode A heuristic in cases where we know mode A can do better.\n",
    "> 3. Fallback Heuristics Mode - intended to be fast and provide functional fallbacks without expectation of optimal performance.\\\n",
    "\n",
    "The recommended workflow is to query either mode A or B and check for support. The first engine config with support is expected to have the best performance. \\\n",
    "Different engines have different support surfaces (in v1.14.1 these are 90, 80, and 70), different operations are supported by different surfaces, generally for the best performance it is recommended to target the highest indexed support surface possible and fall back to lower ones if needed.\n",
    "\n",
    "Front-end docs: https://docs.nvidia.com/deeplearning/cudnn/frontend/v1.14.1/developer/graph-api.html#graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeab9b3",
   "metadata": {},
   "source": [
    "### Defining the Graph\n",
    "\n",
    "Data are represented by edges in the graph, and operations by nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70807985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a graph we can specify the handle (GPU device to execute on), input & output precision and intermediate data precision.\n",
    "graph = cudnn.pygraph(\n",
    "    handle=handle,\n",
    "    name=\"cudnn_graph_0\",\n",
    "    io_data_type=cudnn.data_type.HALF, # (Optional)\n",
    "    compute_data_type=cudnn.data_type.FLOAT, # (Optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232003d0",
   "metadata": {},
   "source": [
    "### Defining Input Tensors\n",
    "\n",
    "`graph.tensor` creates an entry edge to the graph. \n",
    "\n",
    "The main attributes of the tensor class are `dim`, `stride` and `data_type`. Some other attributes are `is_virtual` (mainly used for interior nodes in graph), `is_pass_by_value` for scalar tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e1ea4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269b14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = graph.tensor(\n",
    "    name=\"X\",\n",
    "    dim=[8, 64, 56, 56],\n",
    "    stride=[56 * 56 * 64, 1, 56 * 64, 64],\n",
    "    data_type=cudnn.data_type.HALF,\n",
    ")\n",
    "W = graph.tensor(name=\"W\", dim=[32, 64, 3, 3], stride=[3 * 3 * 64, 1, 3 * 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390dbfc",
   "metadata": {},
   "source": [
    "### Defining Output Tensors\n",
    "\n",
    "Perform a `convolution forward` operation with padding as [1,1] on the input X tensor.\n",
    "\n",
    "Other parameters are `compute_data_type`, `stride`, `dilation`. See `help (cudnn.pygraph.conv_fprop)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f7e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = graph.conv_fprop(\n",
    "    X,\n",
    "    W,\n",
    "    padding=[1, 1],\n",
    "    stride=[1, 1],\n",
    "    dilation=[1, 1],\n",
    "    compute_data_type=cudnn.data_type.FLOAT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d58e8",
   "metadata": {},
   "source": [
    "By default the output of any operation is virtual (does not have device pointer associated). This is because the output can be fed as input to the next operation in graph. In order to terminate the graph, or to mark the tensor non-virtual we need to set the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff35d720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"data_type\":null,\"dim\":[],\"is_pass_by_value\":false,\"is_virtual\":false,\"name\":\"0::Y\",\"pass_by_value\":null,\"reordering_type\":\"NONE\",\"stride\":[],\"uid\":0,\"uid_assigned\":false}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.set_output(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b4475",
   "metadata": {},
   "source": [
    "### Build the Graph\n",
    "\n",
    "Building the graph does the following:\n",
    "\n",
    "- validation of inputs, outputs and output shape deduction.\n",
    "- Lowering pass into the cudnn dialect.\n",
    "- Heuristics query to determine which execution plan to run.\n",
    "- Runtime compilation of the plan if needed\n",
    "\n",
    "In following notebooks, we will see that this function gets split into its constituents to have a better control over each phase.\n",
    "\n",
    "Use the `print` function to inspect the graph after the shape and datatype deduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709e70d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"context\": {\n",
      "        \"compute_data_type\": \"FLOAT\",\n",
      "        \"intermediate_data_type\": null,\n",
      "        \"io_data_type\": \"HALF\",\n",
      "        \"name\": \"\",\n",
      "        \"sm_count\": -1\n",
      "    },\n",
      "    \"cudnn_backend_version\": \"9.13.1\",\n",
      "    \"cudnn_frontend_version\": 11401,\n",
      "    \"json_version\": \"1.0\",\n",
      "    \"nodes\": [\n",
      "        {\n",
      "            \"compute_data_type\": \"FLOAT\",\n",
      "            \"dilation\": [1,1],\n",
      "            \"inputs\": {\n",
      "                \"W\": \"W\",\n",
      "                \"X\": \"X\"\n",
      "            },\n",
      "            \"math_mode\": \"CROSS_CORRELATION\",\n",
      "            \"name\": \"0\",\n",
      "            \"outputs\": {\n",
      "                \"Y\": \"0::Y\"\n",
      "            },\n",
      "            \"post_padding\": [1,1],\n",
      "            \"pre_padding\": [1,1],\n",
      "            \"stride\": [1,1],\n",
      "            \"tag\": \"CONV_FPROP\"\n",
      "        }\n",
      "    ],\n",
      "    \"tensors\": {\n",
      "        \"0::Y\": {\n",
      "            \"data_type\": \"HALF\",\n",
      "            \"dim\": [8,32,56,56],\n",
      "            \"is_pass_by_value\": false,\n",
      "            \"is_virtual\": false,\n",
      "            \"name\": \"0::Y\",\n",
      "            \"pass_by_value\": null,\n",
      "            \"reordering_type\": \"NONE\",\n",
      "            \"stride\": [100352,1,1792,32],\n",
      "            \"uid\": 3,\n",
      "            \"uid_assigned\": true\n",
      "        },\n",
      "        \"W\": {\n",
      "            \"data_type\": \"HALF\",\n",
      "            \"dim\": [32,64,3,3],\n",
      "            \"is_pass_by_value\": false,\n",
      "            \"is_virtual\": false,\n",
      "            \"name\": \"W\",\n",
      "            \"pass_by_value\": null,\n",
      "            \"reordering_type\": \"NONE\",\n",
      "            \"stride\": [576,1,192,64],\n",
      "            \"uid\": 1,\n",
      "            \"uid_assigned\": true\n",
      "        },\n",
      "        \"X\": {\n",
      "            \"data_type\": \"HALF\",\n",
      "            \"dim\": [8,64,56,56],\n",
      "            \"is_pass_by_value\": false,\n",
      "            \"is_virtual\": false,\n",
      "            \"name\": \"X\",\n",
      "            \"pass_by_value\": null,\n",
      "            \"reordering_type\": \"NONE\",\n",
      "            \"stride\": [200704,1,3584,64],\n",
      "            \"uid\": 2,\n",
      "            \"uid_assigned\": true\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "graph.build([cudnn.heur_mode.A])\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476e20f",
   "metadata": {},
   "source": [
    "### Execute the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf38157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_gpu = torch.randn(\n",
    "    8, 64, 56, 56, requires_grad=False, device=\"cuda\", dtype=torch.float16\n",
    ").to(memory_format=torch.channels_last)\n",
    "W_gpu = torch.randn(\n",
    "    32, 64, 3, 3, requires_grad=False, device=\"cuda\", dtype=torch.float16\n",
    ").to(memory_format=torch.channels_last)\n",
    "Y_gpu = torch.zeros(\n",
    "    8, 32, 3, 3, requires_grad=False, device=\"cuda\", dtype=torch.float16\n",
    ").to(memory_format=torch.channels_last)\n",
    "workspace = torch.empty(graph.get_workspace_size(), device=\"cuda\", dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83191ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executes the graph on the GPU device\n",
    "graph.execute({X: X_gpu, W: W_gpu, Y: Y_gpu}, workspace, handle=handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db30aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.0922e+01, -5.9062e+00,  4.3188e+01],\n",
      "          [-2.9688e+01, -1.3633e+01, -9.3203e+00],\n",
      "          [ 2.1547e+01,  9.0312e+00, -2.0977e+00]],\n",
      "\n",
      "         [[ 9.8047e+00,  3.7656e+01, -2.9980e-01],\n",
      "          [-2.2953e+01,  2.2688e+01,  1.7266e+01],\n",
      "          [-2.6438e+01, -1.0719e+01, -2.4781e+01]],\n",
      "\n",
      "         [[-5.3750e+00,  3.0781e+00, -1.1133e+01],\n",
      "          [-6.0117e+00,  1.4852e+01,  4.5977e+00],\n",
      "          [-1.2219e+01, -4.9180e+00,  2.1547e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0656e+01,  8.1328e+00,  3.2719e+01],\n",
      "          [-7.8008e+00, -2.4961e+00, -2.1922e+01],\n",
      "          [ 8.1875e+00,  4.7469e+01,  1.9000e+01]],\n",
      "\n",
      "         [[-9.6328e+00,  3.8887e+00,  3.2031e+00],\n",
      "          [ 1.0141e+01,  3.9121e+00, -1.7783e+00],\n",
      "          [-1.6078e+01, -7.2938e+01,  3.7000e+01]],\n",
      "\n",
      "         [[ 1.7000e+01,  2.7984e+01,  3.1426e+00],\n",
      "          [-1.0094e+01,  9.1250e+00,  3.4375e+01],\n",
      "          [-3.1078e+01, -8.6250e+00,  1.5180e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8234e+01,  2.6077e-02,  9.1406e+00],\n",
      "          [ 3.5801e+00, -2.2469e+01,  1.1492e+01],\n",
      "          [ 3.9156e+01,  9.1562e+00,  1.1234e+01]],\n",
      "\n",
      "         [[-2.2875e+01,  5.0078e+00, -1.4586e+01],\n",
      "          [ 1.9795e+00, -6.3789e+00,  1.6781e+01],\n",
      "          [-8.9062e+00, -2.5984e+01,  3.4375e+01]],\n",
      "\n",
      "         [[-3.5625e+00, -3.2070e+00, -1.4277e+00],\n",
      "          [ 8.7344e+00,  7.4648e+00,  1.6219e+01],\n",
      "          [ 3.3281e+01,  4.4922e+00, -4.8047e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1305e+01,  3.1547e+01,  6.6445e+00],\n",
      "          [-2.2766e+01, -1.1969e+01, -1.5484e+01],\n",
      "          [ 2.3328e+01,  1.0400e+00, -3.4500e+01]],\n",
      "\n",
      "         [[-3.5719e+01,  2.5375e+01, -1.4242e+01],\n",
      "          [ 7.3945e+00,  2.1031e+01, -1.2625e+01],\n",
      "          [ 9.8672e+00, -1.2984e+01, -4.1750e+01]],\n",
      "\n",
      "         [[ 1.1562e+01, -2.6211e+00,  1.1375e+01],\n",
      "          [ 3.6156e+01,  8.3906e+00, -3.0844e+01],\n",
      "          [-1.2164e+01, -1.8469e+01, -1.0453e+01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0156e+00, -1.2031e+01,  2.0016e+01],\n",
      "          [ 7.9414e+00,  1.4250e+01,  1.0117e+01],\n",
      "          [-3.8812e+01,  9.0078e+00, -9.1484e+00]],\n",
      "\n",
      "         [[-1.7844e+01, -3.6781e+01,  2.0094e+01],\n",
      "          [-9.5781e+00,  1.8781e+01, -2.9121e+00],\n",
      "          [-3.6750e+01, -2.3656e+01, -1.6875e+00]],\n",
      "\n",
      "         [[ 3.5020e+00,  1.3213e+00, -1.8516e+01],\n",
      "          [ 4.3477e+00,  8.0938e+01,  7.1445e+00],\n",
      "          [ 1.4523e+01,  7.6836e+00,  4.8320e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2484e+01,  1.2852e+01, -3.2219e+01],\n",
      "          [ 1.9969e+01, -2.0625e+01, -2.3250e+01],\n",
      "          [ 4.6172e+00, -3.4004e+00,  2.6031e+01]],\n",
      "\n",
      "         [[ 2.3828e+00, -1.2156e+01, -6.1953e+00],\n",
      "          [-3.1969e+01,  6.4648e+00, -1.1617e+01],\n",
      "          [ 8.9141e+00, -1.9125e+01,  7.3711e+00]],\n",
      "\n",
      "         [[-7.4375e+00, -2.7188e+01, -8.5000e+00],\n",
      "          [ 2.7062e+01,  1.7344e+01,  1.1828e+01],\n",
      "          [ 5.2500e+00, -7.6875e+00,  3.2969e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5797e+01,  3.1203e+01, -1.7688e+01],\n",
      "          [-1.5508e+00, -1.1883e+01,  8.4688e+00],\n",
      "          [ 9.0430e-01,  3.1312e+01,  2.3008e+00]],\n",
      "\n",
      "         [[-3.6250e+00,  3.0109e+01,  1.8812e+01],\n",
      "          [ 3.3469e+01, -1.6953e+01, -9.3281e+00],\n",
      "          [-5.4844e+00,  1.9109e+01, -1.1648e+01]],\n",
      "\n",
      "         [[ 1.4199e+00, -1.9438e+01, -5.5078e+00],\n",
      "          [ 1.8969e+01,  7.7930e+00, -2.0234e+01],\n",
      "          [-5.5000e+01, -2.1922e+01, -8.4766e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8391e+01,  5.8359e+00, -2.8641e+01],\n",
      "          [-2.8164e+00, -2.1387e+00,  9.1953e+00],\n",
      "          [-3.5742e+00, -1.0695e+01, -1.7812e+00]],\n",
      "\n",
      "         [[ 1.2648e+01, -7.3008e+00,  8.5781e+00],\n",
      "          [ 1.5703e+01,  1.8359e+01, -1.0383e+01],\n",
      "          [ 2.6984e+01, -2.0141e+01,  6.3516e+00]],\n",
      "\n",
      "         [[-1.3695e+01, -2.7422e+01,  2.6938e+01],\n",
      "          [-2.7188e+01,  4.5438e+01,  3.6719e+00],\n",
      "          [-9.2031e+00,  1.2000e+01, -1.8781e+01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0312e-01,  1.6656e+01, -5.0508e+00],\n",
      "          [-1.0430e+01, -3.4812e+01, -1.0586e+00],\n",
      "          [-1.4000e+01,  5.8242e+00, -1.8406e+01]],\n",
      "\n",
      "         [[ 3.3781e+01, -8.9766e+00,  3.7129e+00],\n",
      "          [ 1.4508e+01, -6.6523e+00,  4.3320e+00],\n",
      "          [-1.5258e+01,  4.0781e+00,  5.6031e+01]],\n",
      "\n",
      "         [[ 1.3945e+01,  1.4758e+01,  1.6375e+01],\n",
      "          [ 2.9102e+00, -2.7578e+00, -1.1234e+01],\n",
      "          [-2.5594e+01,  8.2422e+00,  2.2734e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.5000e+00,  1.4844e+00,  5.1938e+01],\n",
      "          [ 1.2789e+01,  1.8516e+01,  1.7109e+01],\n",
      "          [-8.3594e+00,  2.6594e+01,  2.3875e+01]],\n",
      "\n",
      "         [[-8.3203e+00, -3.6031e+01,  1.9484e+01],\n",
      "          [ 4.7188e+00,  6.6133e+00, -1.3781e+01],\n",
      "          [ 3.8781e+01, -2.7938e+01,  1.3453e+01]],\n",
      "\n",
      "         [[ 2.9156e+01,  8.9844e+00,  2.0918e+00],\n",
      "          [ 4.5688e+01,  1.8438e+01,  6.4062e+01],\n",
      "          [-2.2297e+01,  3.3500e+01,  3.9883e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8188e+01,  2.8734e+01,  1.3672e+01],\n",
      "          [-2.5281e+01,  2.0797e+01,  2.1156e+01],\n",
      "          [ 4.3555e+00, -1.6281e+01, -4.5078e+00]],\n",
      "\n",
      "         [[ 3.2793e+00, -8.9766e+00, -5.2969e+00],\n",
      "          [-1.9941e+00,  4.6582e-01,  4.4961e+00],\n",
      "          [ 1.3398e+01, -9.5625e+00, -4.4969e+01]],\n",
      "\n",
      "         [[ 2.0016e+01,  2.1688e+01,  1.5805e+01],\n",
      "          [ 5.1758e+00,  3.3219e+01, -5.1719e+00],\n",
      "          [ 1.6141e+01, -1.0711e+01, -1.9609e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2125e+01, -3.0094e+01,  8.3594e+00],\n",
      "          [ 2.6133e+00,  1.6984e+01,  3.3438e+01],\n",
      "          [-7.4766e+00, -2.1969e+01,  7.1953e+00]],\n",
      "\n",
      "         [[ 2.3609e+01, -1.1672e+01, -1.6125e+01],\n",
      "          [ 2.7016e+01, -3.3125e+01, -5.0281e+01],\n",
      "          [-4.2938e+01,  3.3906e+01, -1.2477e+01]],\n",
      "\n",
      "         [[ 1.0172e+01,  5.5000e+00,  5.9594e+01],\n",
      "          [-3.5562e+01, -4.9500e+01, -4.1812e+01],\n",
      "          [-3.8906e+01, -2.5172e+01, -1.6891e+01]]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(Y_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af169ce3",
   "metadata": {},
   "source": [
    "#### Free GPU device Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1dff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.destroy_handle(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
